{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514a00b6",
   "metadata": {},
   "source": [
    "@dzhang203\n",
    "2022-04\n",
    "\n",
    "[Book Ref: Chapter 19](https://matheusfacure.github.io/python-causality-handbook/19-Evaluating-Causal-Models.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739e75c6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6600859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daz/hello_world/tell_me_why/env/lib/python3.8/site-packages/statsmodels/compat/pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import Int64Index as NumericIndex\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from toolz import curry\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a185750",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87e8c41",
   "metadata": {},
   "source": [
    "## Evaluating Causal Models\n",
    "The goal of a simple causal model is to understand the effect of some treatment $t$ on some outcome $y$, conditional on covariates $x$, i.e. $\\frac{\\partial y}{\\partial t}(t|x)$.\n",
    "\n",
    "How do we know that a causal model is effectively capturing that true derivative? In academic settings and learning exercises (like this one!), we can generate synthetic data from some DGP where we _know_ the real $\\frac{\\partial y}{\\partial t}(t|x)$--by generating multiple counterfactual outcomes for the same $x$--and see how well our estimated $\\hat{\\frac{\\partial y}{\\partial t}}(t|x)$ predicts the true treatment effects.\n",
    "\n",
    "However, in reality, we won't have different $y$'s for the same $x$ at different intervention levels $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca493c62",
   "metadata": {},
   "source": [
    "## One Weird Trick: Aggregate on $x$\n",
    "If $x$ is atomic, then you're never going to have different $y$'s for the same $x$ at different intervention levels $t$. But if you condition on $x$ that includes multiple observation units, then you'll actually be able to observe $\\frac{\\partial y}{\\partial t}(t|x)$!\n",
    "\n",
    "Note that this is only going to be possible if the variation in $t|x$ is actually exogenous. (Note to self: if it's not, maybe estimate a model to orthogonalize it? Or, manually extract out the random (wiggle) component?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c364bf",
   "metadata": {},
   "source": [
    "# Fitting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02491a84",
   "metadata": {},
   "source": [
    "We load data from [github:matheusfacure/python-causality-handbook/data](https://github.com/matheusfacure/python-causality-handbook/tree/master/causal-inference-for-the-brave-and-true/data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e21df0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5)\n",
      "(5000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>weekday</th>\n",
       "      <th>cost</th>\n",
       "      <th>price</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.7</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   temp  weekday  cost  price  sales\n",
       "0  25.8        1   0.3      7    230\n",
       "1  22.7        3   0.5      4    190\n",
       "2  33.7        7   1.0      5    237\n",
       "3  23.0        4   0.5      5    193\n",
       "4  24.4        1   1.0      3    252"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices = pd.read_csv('../data/ice_cream_sales.csv')  # loads non-exogenous data\n",
    "prices_exog = pd.read_csv('../data/ice_cream_sales_rnd.csv')  # loads exogenous (DGP'd) data\n",
    "print(prices.shape)\n",
    "print(prices_exog.shape)\n",
    "prices_exog.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5b7543",
   "metadata": {},
   "source": [
    "The first model we'll train will be a linear regression with interactions so that elasticity can vary between units:\n",
    "\n",
    "$$ sales_i = \\beta_0 + \\beta_1 price_i + \\beta_2 X_i + \\beta_3 X_i price_i + \\epsilon_i $$\n",
    "\n",
    "After fitting this model, we'll be able to make elasticity predictions:\n",
    "\n",
    "$$ \\hat{ \\frac{\\partial sales}{\\partial price}}(price_i, X_i) = \\hat{\\beta_2} + \\hat{\\beta_3} X_i $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b74f23",
   "metadata": {},
   "source": [
    "Refer to [statsmodels formulas examples](https://www.statsmodels.org/stable/example_formulas.html) if needed; below, the \\* operator also includes the individual columns that were multiplied together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9447734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = smf.ols(\"sales ~ price*temp + price*C(weekday) + price*temp\", data=prices).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d24a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e494ced2",
   "metadata": {},
   "source": [
    "# Misc Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c592a664",
   "metadata": {},
   "source": [
    "Looking ahead in Ch. 19, Matheus suggests plotting cumulative elasticity curves. What this means is, we're going to collect the estimated elasticities by groups $x$, sort them into high-to-low groups, and then visually see how well-ordered they are. Additionally, we're going to look at how heterogeneous the treatment effects really are, which should give us insight into how much headroom we can actually get from personalization.\n",
    "\n",
    "However--not covered in Matheus's material--the fundamental model evaluation should still come from looking error in the predicted elasticities themselves. And in this case, we should try to get a test sample with exogenous variation and group them (and potentially orthogonalize the treatment variable) in order to obtain elasticity estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e323d714",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
